---
title: "Rapid access to..."
author: "Loredo, Kamienkowski, Jaichenco"
date: "  /2018"
output: word_document
---
## Experiment 1: Acceptability judgment
### Data Analysis 
  
Data and libraries loading.
    
```{r, echo=TRUE, message=FALSE, warning=FALSE}

library(readr)
library(lme4)
library(multcomp)
library(ggplot2)

todoCUANT <- read.csv2("acepTodoCuant.csv", sep = ";")
control <- read.csv2("acepTodoCONTR.csv", sep = ";")

```


##### Control stimuli  

Print data structure. For condition EAC is highly acceptable and EIC is highly unnaceptable.

```{r}
head(control[c(1,2,3,5,6,7)])
```

Histogram for distribution. 

```{r}
plot_contr <- ggplot(data=control, aes(aceptabilidad)) + geom_histogram(binwidth=0.5)  + ggtitle("Distribution HUS, HAS")
plot_contr + xlab("Aceptability rating") + ylab("n") + scale_x_continuous(breaks = 0:6) + theme_classic() + theme(plot.title = element_text(hjust = 0.5, size = 11))
```

Following a Norman (2010), we decided to use an LMM model with this distribution. Nevertheless, we include at the end non parametric test (Kruskal and Wilconxon tests) that showed similar results with less conservative p-values. 


Descriptive statistics of the data. Condition, mean, and standar deviation are indicated. 


```{r, echo=TRUE, message=FALSE, warning=FALSE}
EAC <- control$aceptabilidad[control$condicion == 'EAC']
EIC <- control$aceptabilidad[control$condicion == 'EIC']

meanControl  <- c(mean(EAC), mean(EIC))
sdControl    <- c(sd(EAC), sd(EIC))
filControl   <- c('HAS', 'HUS')
resumen_control <- data.frame(filControl, meanControl, sdControl)
colnames(resumen_control) <- c('Condition', 'Mean', 'SD')
resumen_control
```


We show a violin plot for both conditions.

```{r}

controlPlot <- control
controlPlot$condition <- ''


for(i in 1:length(controlPlot[,1])){
  if(controlPlot$condicion[i] == 'EAC'){
    controlPlot$condition[i] <- 'HAS'
  } else {
    controlPlot$condition[i] <- 'HUS'
  }}



violinControl <- ggplot(controlPlot, aes(factor(condition), aceptabilidad, fill = factor(condition)))
violinControl + geom_violin() + geom_crossbar(stat="summary", fun.y=mean, fun.ymax=mean, fun.ymin=mean, fatten=1, width=1) + theme_minimal() + xlab('Condition') + ylab('Rating') + labs(fill = 'Condition', subtitle = 'Control stimuli')

```

###### LMM
Our model uses condition as fixed effect and subject and items as random effects. 
We use glht() function of {multcomp} library to perform multiple comparisons with Tukey method.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
model_control <- lmer(aceptabilidad ~ condicion + (1|sujeto) + (1|item), data=control, REML = FALSE)
summary(model_control)
summary(glht(model_control, linfct=mcp(condicion="Tukey")))
```

Our analysis show that the differences between HAS and HUS are highly significant (p < .0001)

#### Critical stimuli (dialogs with quantifiers)

Print data structure. 

CNS = LB + Only some
CNA = LB + Some 
FPS = UB + Only some
FPA = UB + Some


```{r}
head(todoCUANT[c(1,2,3,5,6,7)])
```

Histogram for distribution

```{r, echo=TRUE, message=FALSE, warning=FALSE}
ac <- ggplot(data=todoCUANT, aes(todoCUANT$aceptabilidad)) + geom_histogram(binwidth=0.5)  + ggtitle("Distribution for critical stimuli")
ac + xlab("Aceptability rate") + ylab("n") + scale_x_continuous(breaks = 0:6) + theme_classic() + theme(plot.title = element_text(hjust = 0.5, size = 11))
```

Descriptive statistics of the data. Condition, mean, and standar deviation are indicated. 

```{r}
CNA <- todoCUANT$aceptabilidad[todoCUANT$condicion == 'CNA']
CNS <- todoCUANT$aceptabilidad[todoCUANT$condicion == 'CNS']
FPA <- todoCUANT$aceptabilidad[todoCUANT$condicion == 'FPA']
FPS <- todoCUANT$aceptabilidad[todoCUANT$condicion == 'FPS']

meanAC <- c(mean(CNA), mean(CNS), mean(FPA), mean(FPS))
sdAC   <- c(sd(CNA), sd(CNS), sd(FPA), sd(FPS))
condAC <- c('LB + S', 'LB + O', 'UB + S', 'UB + O')
resAC <- data.frame(condAC, meanAC, sdAC)
colnames(resAC) <- c('Condition', 'Mean', 'SD')
resAC
```


###### LMM 
The LMM model uses condition as a fixed effect and subject and ítem as random effects. Multiple comparisons with Tukey method were performed.


```{r}
maceptabilidad <- lmer(aceptabilidad ~ condicion + (1|sujeto) + (1|item), data=todoCUANT, REML = FALSE)
summary(maceptabilidad)
summary(glht(maceptabilidad, linfct=mcp(condicion="Tukey")))

```

Our analysis shows that CNS (LB + O) ratings is significantly different from the other conditions, and that the other conditions do not differ.

### Non parametrical statistics.
For this analysis we use the subject mean for each condition. Each datapoint for each subject consists in the mean for the acceptability rating mean for that condition. To perform this we used {dplyr} library.


Load dplyr
```{r, echo=TRUE, message=FALSE, warning=FALSE}
library(dplyr)
```

Mean by condition for subject
```{r}
controlEIC <- summarise(group_by(control[control$condicion == 'EIC',], sujeto), mean=mean(aceptabilidad), condicion='EIC')
controlEAC <- summarise(group_by(control[control$condicion == 'EAC',], sujeto), mean=mean(aceptabilidad), condicion='EAC')

noParControl <- rbind(controlEIC, controlEAC)


dataCNA <- summarise(group_by(todoCUANT[todoCUANT$condicion == 'CNA',], sujeto), mean=mean(aceptabilidad), condicion='CNA')
dataCNS <- summarise(group_by(todoCUANT[todoCUANT$condicion == 'CNS',], sujeto), mean=mean(aceptabilidad), condicion='CNS')
dataFPA <- summarise(group_by(todoCUANT[todoCUANT$condicion == 'FPA',], sujeto), mean=mean(aceptabilidad), condicion='FPA')
dataFPS <- summarise(group_by(todoCUANT[todoCUANT$condicion == 'FPS',], sujeto), mean=mean(aceptabilidad), condicion='FPS')

noParCUANT <- rbind(dataCNA, dataCNS, dataFPA, dataFPS)

```



#### Control stimuli

Create vectors for HAS and HUS
```{r}
noParEAC <- noParControl$mean[noParControl$condicion == 'EAC']
noParEIC <- noParControl$mean[noParControl$condicion == 'EIC']
```

Wilcoxon test

```{r}
wilcox.test(noParEAC, noParEIC)
```

The p-value obtained is smaller for this test. The downside is that item is not included as a random effect for this model so we incurr in the language-as-fixed effect falacy. Therefore, LMM models are more appropriate. 


#### Critical stimuli

Data vector for each condition.
```{r}
noParCNA <- noParCUANT$mean[noParCUANT$condicion == 'CNA']
noParCNS <- noParCUANT$mean[noParCUANT$condicion == 'CNS']
noParFPA <- noParCUANT$mean[noParCUANT$condicion == 'FPA']
noParFPS <- noParCUANT$mean[noParCUANT$condicion == 'FPS']
```

Kruskal-Wallis test to analyze inter-condition differences.

```{r}
kruskal.test(noParCNS, noParCNA, noParFPA, noParFPS)
```

P-value of 0.01 shows that there is differences between conditions. We proceed with multiple comparisons using Wilcoxon. In this case we will decide to use a more conservative method than Tukey, that is Bonferroni correction where the Alpha p value of 0.05 is divided by the number of comparisons performed. In our case, there were performed 6 comparisons. Thus, the alpha is .008.

```{r}
CNSxCNA <- wilcox.test(noParCNS, noParCNA)
FPAxCNS <- wilcox.test(noParFPA, noParCNS)
FPSxCNS <- wilcox.test(noParFPS, noParCNS)
FPAxCNA <- wilcox.test(noParFPS, noParFPA)
FPSxCNA <- wilcox.test(noParFPS, noParCNA)
FPSxFPA <- wilcox.test(noParFPS, noParFPA)

pvalores <- c(CNSxCNA$p.value,FPAxCNS$p.value, FPSxCNS$p.value, FPAxCNA$p.value, FPSxCNA$p.value, FPSxFPA$p.value)
W <- c(CNSxCNA$statistic,FPAxCNS$statistic, FPSxCNS$statistic, FPAxCNA$statistic, FPSxCNA$statistic, FPSxFPA$statistic)
comparacion <- c('LB + S x LB + O', 'UB + S x LB + O', 'UB + O x LB + O', 'UB + S x LB + S', 'UB + O x LB + S', 'UB + O x UB + S')

reporte <- data.frame(comparacion, W, format(pvalores, scientific = FALSE))
colnames(reporte) <- c('Comparison', 'W', 'p-value')

reporte

```

The results for the table above are the same than for LMM model performed. That we reproduce below:

```{r}
summary(glht(maceptabilidad, linfct=mcp(condicion="Tukey")))
```



## Experiment 2: self-paced reading task

### Data analysis 
Data and libraries loading. 

```{r, warning=FALSE}
library(stringr)

datos <- read.delim('datosFinal.csv', sep = ';')
#Change columns to correct class
datos$rt <- as.numeric(as.character(datos$rt))
datos$sexo <- as.numeric(as.character(datos$sexo))
datos$edad <- as.numeric(as.character(datos$edad))
datos$orden <- as.numeric(as.character(datos$orden))
datos$rtLog <- log10(datos$rt)
datos$nacionalidad <- NULL
datos$educacion <- NULL

#Create groups by segment
ind_condicion <- datos$condicion == 'CNA' | datos$condicion == 'FPA' | datos$condicion == 'FPS'
fraseCuant <- datos[ind_condicion & datos$frase == 'blanco_CUANT',]
fraseRest  <- datos[ind_condicion & datos$frase == 'blanco_REST',]
fraseCntx  <- datos[ind_condicion & datos$frase == 'CNTX',]
frasePreg <- datos[ind_condicion & datos$frase == 'PREG',]
```



Show data structure.

```{r}
datos[34:39,]
```


#### Accuracy
Mean of responses to measure the accuracy (1 = correct / 0 = incorrect)

```{r}
print(paste('Correct answers: ',  round(mean(datos$aciertos, na.rm = TRUE)*100, 2), '%',  sep = ''))
```


#### Outliers trimming for RT
Following Baayen (2008) we perform the trimming of the outliers.

##### Context
```{r}
boxplot(fraseCntx$rtLog)
hist(fraseCntx$rtLog, breaks = 30)
max(fraseCntx$rtLog)
min(fraseCntx$rtLog)
largoCntx <- length(fraseCntx$rt)
fraseCntx <- fraseCntx[fraseCntx$rtLog < 3.9 & fraseCntx$rtLog > 2.9,]
cantidadElimCntx <- largoCntx - length(fraseCntx$rt)
porcenElimCntx <- (cantidadElimCntx/largoCntx) * 100
print(paste('Deleted ', round(porcenElimCntx, digits = 3), '% of observations.', sep = ''))
max(fraseCntx$rtLog)
min(fraseCntx$rtLog)
boxplot(fraseCntx$rtLog)
hist(fraseCntx$rtLog, breaks = 30)
```


##### Question
```{r}
boxplot(frasePreg$rtLog)
hist(frasePreg$rtLog, breaks = 30)
max(frasePreg$rtLog)
min(frasePreg$rtLog)
largoPreg <- length(frasePreg$rt)
frasePreg <- frasePreg[frasePreg$rtLog < 3.5 & frasePreg$rtLog > 2.6,]
cantidadElimPreg <- largoPreg - length(frasePreg$rt)
porcenElimPreg <- (cantidadElimPreg/largoPreg) * 100
print(paste('Deleted ', round(porcenElimPreg, digits = 3), '% of observations.', sep = ''))
max(frasePreg$rtLog)
min(frasePreg$rtLog)
boxplot(frasePreg$rtLog)
hist(frasePreg$rtLog, breaks = 30)
```


##### Quantifier segment
```{r}
boxplot(fraseCuant$rtLog)
hist(fraseCuant$rtLog, breaks = 30)
max(fraseCuant$rtLog)
min(fraseCuant$rtLog)
largocuant <- length(fraseCuant$rt)
fraseCuant <- fraseCuant[fraseCuant$rtLog < 3.6 & fraseCuant$rtLog > 2.7,]
cantidadElim <- largocuant - length(fraseCuant$rt)
porcenElim <- (cantidadElim/largocuant) * 100
print(paste('Deleted ', round(porcenElim, digits = 3), '% of observations.', sep = ''))
boxplot(fraseCuant$rtLog)
hist(fraseCuant$rtLog, breaks = 30)
max(fraseCuant$rtLog)
min(fraseCuant$rtLog)
```

##### The rest segment
```{r}
boxplot(fraseRest$rtLog)
hist(fraseRest$rtLog, breaks = 30)
max(fraseRest$rtLog)
min(fraseRest$rtLog)
largorest <- length(fraseRest$rt)
fraseRest <- fraseRest[fraseRest$rtLog < 3.6 & fraseRest$rtLog > 2.5,]
cantidadElimRest <- largorest - length(fraseRest$rt)
porcenElimRest <- (cantidadElimRest/largorest) * 100
print(paste('Deleted ', round(porcenElimRest, digits = 3), '% of observations.', sep = ''))
max(fraseRest$rtLog)
min(fraseRest$rtLog)
boxplot(fraseRest$rtLog)
hist(fraseRest$rtLog, breaks = 30)

```


#### Context
##### Data description
Violin plot of rtLog for UB and LB contexts.
```{r}
violinContext <- ggplot(fraseCntx, aes(factor(contexto), rtLog, fill = factor(contexto)))
violinContext + geom_violin(trim = FALSE) + geom_crossbar(stat="summary", fun.y=mean, fun.ymax=mean, fun.ymin=mean, fatten=1, width=1) + theme_minimal() + xlab('Conditions') + ylab('rtLog') + labs(fill = 'Condition', subtitle = 'Context segment')
```

Mean and SD
```{r}
descriptiveContext <- fraseCntx %>%
  group_by(contexto) %>%
  summarise(mean = mean(rt, na.rm = TRUE), sd = sd(rt, na.rm = TRUE))
descriptiveContext$contexto <- c('LB', 'UB')
colnames(descriptiveContext) <- c('Context', 'Mean', 'SD')
print(descriptiveContext)
```

##### LMM
LMM for comparing contexts. Context as fixed effect. Subject and item as random intercepts. 


```{r}
m1_cntx <- lmer(rtLog ~ contexto + (1|sujeto) + (1|idnumero), data=fraseCntx, REML = FALSE)
summary(m1_cntx)
summary(glht(m1_cntx, linfct=mcp(contexto = "Tukey")))
```


#### Question
##### Data description
Violin plot of rtLog for UB and LB contexts.
```{r}
violinQuest <- ggplot(frasePreg, aes(factor(contexto), rtLog, fill = factor(contexto)))
violinQuest + geom_violin(trim = FALSE) + geom_crossbar(stat="summary", fun.y=mean, fun.ymax=mean, fun.ymin=mean, fatten=1, width=1) + theme_minimal() + xlab('Conditions') + ylab('rtLog') + labs(fill = 'Condition', subtitle = 'Question segment')
```

Mean and SD
```{r}
descriptiveQuest <- frasePreg %>%
  group_by(contexto) %>%
  summarise(mean = mean(rt, na.rm = TRUE), sd = sd(rt, na.rm = TRUE))
descriptiveQuest$contexto <- c('LB', 'UB')
colnames(descriptiveQuest) <- c('Context', 'Mean', 'SD')
print(descriptiveQuest)
```

##### LMM
LMM for comparing contexts. Context as fixed effect. Subject and item as random intercepts. 


```{r}
m1_quest <- lmer(rtLog ~ contexto + (1|sujeto) + (1|idnumero), data=frasePreg, REML = FALSE)
summary(m1_quest)
summary(glht(m1_quest, linfct=mcp(contexto = "Tukey")))
```


#### Quantifier segment
##### Data description

Violin plot of rtLog for quantifier segment with 'Some' comparing UB and LB contexts.

```{r}
violinQuant <- ggplot(fraseCuant[fraseCuant$cuantificador == 'A',], aes(factor(contexto), rtLog, fill = factor(contexto)))
violinQuant + geom_violin(trim = FALSE) + geom_crossbar(stat="summary", fun.y=mean, fun.ymax=mean, fun.ymin=mean, fatten=1, width=1) + theme_minimal() + xlab('Conditions') + ylab('rtLog') + labs(fill = 'Condition', subtitle = 'Context segment')
```

Mean and SD for Reading times (not log transformed)
```{r}
descriptiveQuant <- fraseCuant[fraseCuant$cuantificador == 'A',] %>%
  group_by(contexto) %>%
  summarise(mean = mean(rt, na.rm = TRUE), sd = sd(rt, na.rm = TRUE))
descriptiveQuant$contexto <- c('LB + Some', 'UB + Some')
colnames(descriptiveQuant) <- c('Condition', 'Mean', 'SD')
print(descriptiveQuant)
```


##### LMM
LMM for comparing segments with 'Some'. Context as fixed effect. Subject and item as random intercepts. 
```{r}
m1_cuant <- lmer(rtLog ~ contexto + (1|sujeto) + (1|idnumero), data=fraseCuant[fraseCuant$cuantificador == 'A',], REML = FALSE)
summary(m1_cuant)
summary(glht(m1_cuant, linfct=mcp(contexto = "Tukey")))
```


p-value of .0181 shows that the mean is significantly different. The small difference in reading times raw values could be explained by the effect of the learning curve of the task as can seen in the graphic below. (Similar to the effect observed in Spotorno and Noveck (JEP:General))

```{r, message=FALSE, warning=FALSE}

LbSomeScatter <- ggplot(fraseCuant[fraseCuant$cuantificador == 'A',], aes(orden, rtLog, colour = contexto))

LbSomeScatter + geom_point(aes(colour = factor(contexto))) + geom_smooth(data = fraseCuant[fraseCuant$cuantificador == 'A' & fraseCuant$contexto == 'CN',]) + geom_smooth(data = fraseCuant[fraseCuant$cuantificador == 'A' & fraseCuant$contexto == 'FP',])

```

The first segment before trial order 100 shows the begining of the learning of the task. Between 100 and 200 there is a clear difference between UB and LB contexts. Later in the task, after 200 trial order (170 trial order is the middle point of trial order) the lines converge given the effect of acclimating to an literal 'some' reading. 

A new description of the data showing only the occurences between these two intervals is showed below and the tendency is clearer.

```{r}
violinQuantRed <- ggplot(fraseCuant[fraseCuant$cuantificador == 'A' & fraseCuant$orden > 100 & fraseCuant$orden < 170 ,], aes(factor(contexto), rtLog, fill = factor(contexto)))
violinQuantRed + geom_violin(trim = FALSE) + geom_crossbar(stat="summary", fun.y=mean, fun.ymax=mean, fun.ymin=mean, fatten=1, width=1) + theme_minimal() + xlab('Conditions') + ylab('rtLog') + labs(fill = 'Condition', subtitle = 'Context segment')
```

Mean and SD

```{r}
descriptiveQuantRed <- fraseCuant[fraseCuant$cuantificador == 'A' & fraseCuant$orden > 100 & fraseCuant$orden < 170 ,] %>%
  group_by(contexto) %>%
  summarise(mean = mean(rt, na.rm = TRUE), sd = sd(rt, na.rm = TRUE))
descriptiveQuantRed$contexto <- c('LB + Some', 'UB + Some')
colnames(descriptiveQuantRed) <- c('Condition', 'Mean', 'SD')
print(descriptiveQuantRed)
```


#### The rest segment

Violin plot of rtLog for 'the rest' segment with comparing UB+S, LB+S and UB + OS contexts.

```{r}
violinRest <- ggplot(fraseRest, aes(factor(condicion), rtLog, fill = factor(condicion)))
violinRest + geom_violin(trim = FALSE) + geom_crossbar(stat="summary", fun.y=mean, fun.ymax=mean, fun.ymin=mean, fatten=1, width=1) + theme_minimal() + xlab('Conditions') + ylab('rtLog') + labs(fill = 'Condition', subtitle = '"the rest" segment')
```

Mean and SD

```{r}
descriptiveRest <- fraseRest %>%
  group_by(condicion) %>%
  summarise(mean = mean(rt, na.rm = TRUE), sd = sd(rt, na.rm = TRUE))
descriptiveRest$condicion <- c('LB + Some', 'UB + Some', 'UB + Only some')
colnames(descriptiveRest) <- c('Condition', 'Mean', 'SD')
print(descriptiveRest)
```


##### LMM
LMM for comparing 'the rest' segments. Context + quantifier as fixed effects. Subject and item as random intercepts. 

```{r}
m1_rest <- lmer(rtLog ~ contexto + cuantificador + (1|sujeto) + (1|idnumero), data=fraseRest, REML = FALSE)
summary(m1_rest)
summary(glht(m1_rest, linfct=mcp(contexto = "Tukey")))
summary(glht(m1_rest, linfct=mcp(cuantificador = "Tukey")))
```






### Referencias

Norman, G. (2010) Likert scales, levels of measurement and the “laws” of statistics. Advances in Health Sciences Education, 15(5), 625–632.  https://www.ncbi.nlm.nih.gov/pubmed/20146096

Baayen H (2008) Analyzing linguistic data: a practical introduction to statistics using R. Cambridge: Cambridge University Press. 390 p.



